{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 보스턴 주택 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 1s 18us/step\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2\n"
     ]
    }
   ],
   "source": [
    "print(train_targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.74511057e+00 1.14801980e+01 1.11044307e+01 6.18811881e-02\n",
      " 5.57355941e-01 6.26708168e+00 6.90106436e+01 3.74027079e+00\n",
      " 9.44059406e+00 4.05898515e+02 1.84759901e+01 3.54783168e+02\n",
      " 1.27408168e+01]\n"
     ]
    }
   ],
   "source": [
    "print(mean) # 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.22929073e+00 2.37382770e+01 6.80287253e+00 2.40939633e-01\n",
      " 1.17147847e-01 7.08908627e-01 2.79060634e+01 2.02770050e+00\n",
      " 8.68758849e+00 1.66168506e+02 2.19765689e+00 9.39946015e+01\n",
      " 7.24556085e+00]\n"
     ]
    }
   ],
   "source": [
    "print(std) # 표준편차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정규화된 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27224633 -0.48361547 -0.43576161 -0.25683275 -0.1652266  -0.1764426\n",
      "  0.81306188  0.1166983  -0.62624905 -0.59517003  1.14850044  0.44807713\n",
      "  0.8252202 ]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.55369355 -0.48361547  1.0283258  -0.25683275  1.03838067  0.23545815\n",
      "  1.11048828 -0.93976936  1.67588577  1.5652875   0.78447637 -3.48459553\n",
      "  2.25092074]\n"
     ]
    }
   ],
   "source": [
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "\n",
    "def build_model(): # 동일한 모델을 여러 번 생성할 것이므로 함수를 만들어 사용합니다.\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이 네트워크의 마지막 층은 하나의 유닛을 가지고 있고 활성화 함수가 없습니다. (선형 층)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 mse(평균 제곱 오차) 손실 함수를 사용하여 컴파일합니다. 회귀 문제에서 널리 사용되는 손실 함수입니다.\n",
    "\n",
    "훈련하는 동안 모니터링을 위해 새로운 지표인 평균 절대 오차(MAE)를 측정합니다. 이는 예측과 타깃 사이 거리의 절댓값입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-겹 검증하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터 포인트가 많지 않기 때문에 검증 세트도 매우 작아집니다. 검증 세트와 훈련 세트로 어떤 데이터 포인터가 선택되었는지에 따라 검증 점수가 크게 달라집니다. 데이터를 K개의 분할로 나누고, K개의 모델을 각각 만들어 K-1개의 분할에서 훈련하고 나머지 분할에서 평가하는 방법입니다. (K-fold cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드 # 0\n",
      "처리중인 폴드 # 1\n",
      "처리중인 폴드 # 2\n",
      "처리중인 폴드 # 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드 #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "    [train_data[:i * num_val_samples],\n",
    "    train_data[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    partial_train_targets = np.concatenate(\n",
    "    [train_targets[:i * num_val_samples],\n",
    "    train_targets[(i + 1) * num_val_samples:]],\n",
    "    axis=0)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1, verbose=0) # verbose=0이므로 훈련 과정이 출력되지 않습니다.\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.9232635498046875, 2.6514081954956055, 2.722653865814209, 2.532093048095703]\n"
     ]
    }
   ],
   "source": [
    "print(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
