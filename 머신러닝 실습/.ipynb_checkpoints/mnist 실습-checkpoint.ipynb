{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의) tensorflow와 keras, pytorch는 깔려있는 것을 전제로 시작한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MNIST란\n",
    "28×28 크기의 0~9사이의 숫자 이미지와 이에 해당하는 레이블(Label)로 구성된 데이터베이스이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집\n",
    "본 실습에서는 keras의 dataset에 포함되어 있는 mnist를 이용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "mnist = datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "print(train_x.shape) # (60000, 28, 28) 뜻 : 28 * 28 크기의 이미지가 60000개 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_x 는 훈련시킬 이미지, train_y 는 훈련시킬 이미지의 답안을 의미한다.\n",
    "\n",
    "test_x 는 모델을 fitting 시킨 이후에 성능을 테스트해보기 위한 이미지,\n",
    "test_y 는 성능 테스트를 위한 이미지들의 답안이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 첫 번째 training data의 답안을 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정말로 그 답이 맞는지 이미지로 확인해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이미지를 출력하기 위해서는 matplotlib.pyplot을 이용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# jupyter notebook에서 matplotlib를 사용하기 위해 추가하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256e5ad6cd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOYElEQVR4nO3dbYxc5XnG8euKbUwxJvHGseMQFxzjFAg0Jl0ZkBFQoVCCIgGKCLGiiFBapwlOQutKUFoVWtHKrRIiSimSKS6m4iWQgPAHmsSyECRqcFmoAROHN+MS4+0aswIDIfZ6fffDjqsFdp5dZs68eO//T1rNzLnnzLk1cPmcmeeceRwRAjD5faDTDQBoD8IOJEHYgSQIO5AEYQeSmNrOjR3i6XGoZrRzk0Aqv9Fb2ht7PFatqbDbPkfS9ZKmSPrXiFhVev6hmqGTfVYzmwRQsDE21K01fBhve4qkGyV9TtLxkpbZPr7R1wPQWs18Zl8i6fmI2BoReyXdJem8atoCULVmwn6kpF+Nery9tuwdbC+33We7b0h7mtgcgGY0E/axvgR4z7m3EbE6InojoneapjexOQDNaCbs2yXNH/X445J2NNcOgFZpJuyPSlpke4HtQyR9SdK6atoCULWGh94iYp/tFZJ+rJGhtzUR8XRlnQGoVFPj7BHxgKQHKuoFQAtxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDWLK7qfp5b/E0/5yOyWbv+ZPz+6bm34sP3FdY9auLNYP+wbLtb/97pD6tYe7/1+cd1dw28V6yffs7JYP+bPHinWO6GpsNveJukNScOS9kVEbxVNAaheFXv234+IXRW8DoAW4jM7kESzYQ9JP7H9mO3lYz3B9nLbfbb7hrSnyc0BaFSzh/FLI2KH7TmS1tv+ZUQ8PPoJEbFa0mpJOsI90eT2ADSoqT17ROyo3e6UdJ+kJVU0BaB6DYfd9gzbMw/cl3S2pM1VNQagWs0cxs+VdJ/tA69zR0T8qJKuJpkpxy0q1mP6tGJ9xxkfKtbfPqX+mHDPB8vjxT/9dHm8uZP+49czi/V/+OdzivWNJ95Rt/bi0NvFdVcNfLZY/9hPD75PpA2HPSK2Svp0hb0AaCGG3oAkCDuQBGEHkiDsQBKEHUiCS1wrMHzmZ4r16269sVj/5LT6l2JOZkMxXKz/9Q1fLdanvlUe/jr1nhV1azNf3ldcd/qu8tDcYX0bi/VuxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0C05/ZUaw/9pv5xfonpw1U2U6lVvafUqxvfbP8U9S3LvxB3drr+8vj5HP/6T+L9VY6+C5gHR97diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHtG1E8wj1xss9q2/a6xeAlpxbru88p/9zzlCcPL9af+MYN77unA67d9bvF+qNnlMfRh197vViPU+v/APG2bxVX1YJlT5SfgPfYGBu0OwbHnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMvvDxfrwq4PF+ot31B8rf/r0NcV1l/z9N4v1OTd27ppyvH9NjbPbXmN7p+3No5b12F5v+7na7awqGwZQvYkcxt8q6d2z3l8paUNELJK0ofYYQBcbN+wR8bCkdx9Hnidpbe3+WknnV9wXgIo1+gXd3Ijol6Ta7Zx6T7S93Haf7b4h7WlwcwCa1fJv4yNidUT0RkTvNE1v9eYA1NFo2Adsz5Ok2u3O6loC0AqNhn2dpItr9y+WdH817QBolXF/N972nZLOlDTb9nZJV0taJelu25dKeknSha1scrIb3vVqU+sP7W58fvdPffkXxforN00pv8D+8hzr6B7jhj0iltUpcXYMcBDhdFkgCcIOJEHYgSQIO5AEYQeSYMrmSeC4K56tW7vkxPKgyb8dtaFYP+PCy4r1md9/pFhH92DPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+CZSmTX7168cV131p3dvF+pXX3las/8UXLyjW478/WLc2/+9+XlxXbfyZ8wzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEkzZnNzgH55arN9+9XeK9QVTD21425+6bUWxvujm/mJ939ZtDW97smpqymYAkwNhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKYuniYv2IVduL9Ts/8eOGt33sg39UrP/O39S/jl+Shp/b2vC2D1ZNjbPbXmN7p+3No5ZdY/tl25tqf+dW2TCA6k3kMP5WSeeMsfx7EbG49vdAtW0BqNq4YY+IhyUNtqEXAC3UzBd0K2w/WTvMn1XvSbaX2+6z3TekPU1sDkAzGg37TZIWSlosqV/Sd+s9MSJWR0RvRPRO0/QGNwegWQ2FPSIGImI4IvZLulnSkmrbAlC1hsJue96ohxdI2lzvuQC6w7jj7LbvlHSmpNmSBiRdXXu8WFJI2ibpaxFRvvhYjLNPRlPmzinWd1x0TN3axiuuL677gXH2RV9+8exi/fXTXi3WJ6PSOPu4k0RExLIxFt/SdFcA2orTZYEkCDuQBGEHkiDsQBKEHUiCS1zRMXdvL0/ZfJgPKdZ/HXuL9c9/8/L6r33fxuK6Byt+ShoAYQeyIOxAEoQdSIKwA0kQdiAJwg4kMe5Vb8ht/2nln5J+4cLylM0nLN5WtzbeOPp4bhg8qVg/7P6+pl5/smHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+ybn3hGL92W+Vx7pvXrq2WD/90PI15c3YE0PF+iODC8ovsH/cXzdPhT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPtBYOqCo4r1Fy75WN3aNRfdVVz3C4fvaqinKlw10FusP3T9KcX6rLXl353HO427Z7c93/aDtrfYftr2t2vLe2yvt/1c7XZW69sF0KiJHMbvk7QyIo6TdIqky2wfL+lKSRsiYpGkDbXHALrUuGGPiP6IeLx2/w1JWyQdKek8SQfOpVwr6fxWNQmgee/rCzrbR0s6SdJGSXMjol8a+QdB0pw66yy33We7b0h7musWQMMmHHbbh0v6oaTLI2L3RNeLiNUR0RsRvdM0vZEeAVRgQmG3PU0jQb89Iu6tLR6wPa9WnydpZ2taBFCFcYfebFvSLZK2RMR1o0rrJF0saVXt9v6WdDgJTD36t4v1139vXrF+0d/+qFj/kw/dW6y30sr+8vDYz/+l/vBaz63/VVx31n6G1qo0kXH2pZK+Iukp25tqy67SSMjvtn2ppJckXdiaFgFUYdywR8TPJI05ubuks6ptB0CrcLoskARhB5Ig7EAShB1IgrADSXCJ6wRNnffRurXBNTOK6359wUPF+rKZAw31VIUVL59WrD9+U3nK5tk/2Fys97zBWHm3YM8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0mkGWff+wflny3e+6eDxfpVxzxQt3b2b73VUE9VGRh+u27t9HUri+se+1e/LNZ7XiuPk+8vVtFN2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJpxtm3nV/+d+3ZE+9p2bZvfG1hsX79Q2cX6x6u9+O+I4699sW6tUUDG4vrDhermEzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6I8hPs+ZJuk/RRjVy+vDoirrd9jaQ/lvRK7alXRUT9i74lHeGeONlM/Aq0ysbYoN0xOOaJGRM5qWafpJUR8bjtmZIes72+VvteRHynqkYBtM5E5mfvl9Rfu/+G7S2Sjmx1YwCq9b4+s9s+WtJJkg6cg7nC9pO219ieVWed5bb7bPcNaU9TzQJo3ITDbvtwST+UdHlE7JZ0k6SFkhZrZM//3bHWi4jVEdEbEb3TNL2ClgE0YkJhtz1NI0G/PSLulaSIGIiI4YjYL+lmSUta1yaAZo0bdtuWdIukLRFx3ajl80Y97QJJ5ek8AXTURL6NXyrpK5Kesr2ptuwqSctsL5YUkrZJ+lpLOgRQiYl8G/8zSWON2xXH1AF0F86gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDHuT0lXujH7FUn/M2rRbEm72tbA+9OtvXVrXxK9NarK3o6KiI+MVWhr2N+zcbsvIno71kBBt/bWrX1J9NaodvXGYTyQBGEHkuh02Fd3ePsl3dpbt/Yl0Vuj2tJbRz+zA2ifTu/ZAbQJYQeS6EjYbZ9j+xnbz9u+shM91GN7m+2nbG+y3dfhXtbY3ml786hlPbbX236udjvmHHsd6u0a2y/X3rtNts/tUG/zbT9oe4vtp21/u7a8o+9doa+2vG9t/8xue4qkZyV9VtJ2SY9KWhYRv2hrI3XY3iapNyI6fgKG7dMlvSnptog4obbsHyUNRsSq2j+UsyLiii7p7RpJb3Z6Gu/abEXzRk8zLul8SV9VB9+7Ql9fVBvet07s2ZdIej4itkbEXkl3STqvA310vYh4WNLguxafJ2lt7f5ajfzP0nZ1eusKEdEfEY/X7r8h6cA04x197wp9tUUnwn6kpF+Nerxd3TXfe0j6ie3HbC/vdDNjmBsR/dLI/zyS5nS4n3cbdxrvdnrXNONd8941Mv15szoR9rGmkuqm8b+lEfEZSZ+TdFntcBUTM6FpvNtljGnGu0Kj0583qxNh3y5p/qjHH5e0owN9jCkidtRud0q6T903FfXAgRl0a7c7O9zP/+umabzHmmZcXfDedXL6806E/VFJi2wvsH2IpC9JWteBPt7D9ozaFyeyPUPS2eq+qajXSbq4dv9iSfd3sJd36JZpvOtNM64Ov3cdn/48Itr+J+lcjXwj/4Kkv+xED3X6+oSkJ2p/T3e6N0l3auSwbkgjR0SXSvqwpA2Snqvd9nRRb/8u6SlJT2okWPM61NtpGvlo+KSkTbW/czv93hX6asv7xumyQBKcQQckQdiBJAg7kARhB5Ig7EAShB1IgrADSfwfs4RxaLJFjqkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = train_x[0]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256e5b84d90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray') # gray 이외에도 RdBu, jet 등이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하나만 더 열어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesImage(54,36;334.8x217.44)\n",
      "답안: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image2 = train_x[1]\n",
    "print(plt.imshow(image2))\n",
    "print('답안:',train_y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 데이터와 답안이 존재하여 이를 이용해 학습하는 것을 <strong>지도 학습(supervised learning)</strong>이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터가 생성되고, 데이터에 Transform 변형을 준다거나 모델에 들어가기 전에 데이터 전처리가 들어감\n",
    "- 이 때 들어갈 때는 Batch로 만들어서 Model에 넣어줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mnist 데이터의 경우 최대 255의 값을 갖는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "때문에 다음의 값들을 0~1 사이의 값으로 변환해주기 위해 255로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x / 255\n",
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 test 데이터 또한 255로 나누어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로젝트를 진행하기 위해 사전학습모델(pre-trained model)을 이용할 수 있다. (대표적으로 이미지에서 강한 힘을 보이는 Resnet 등)\n",
    "\n",
    "이번 실습에서는 keras에서 제공하는 Sequential 모델을 사용하고자 한다.\n",
    "\n",
    "https://keras.io/ko/getting-started/sequential-model-guide/\n",
    "\n",
    "> 모델에는 LeNet, AlexNet, VGG나 ResNet 등 다양하게 설계된 모델이 존재하며, Convolution Layer, Pooling 등 다양한 Layer 층들로 구성되어 있다. 이러한 모델들 안에는 학습 파라미터가 있으며, 이는 곧 모델이 학습하는 대상이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델에 여러 설정을 해주기 위해 다음 코드도 import 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 800us/step - loss: 0.2977 - accuracy: 0.9134\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1455 - accuracy: 0.9570\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1101 - accuracy: 0.9664\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 822us/step - loss: 0.0910 - accuracy: 0.9719\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 2s 868us/step - loss: 0.0763 - accuracy: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256e4540730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0666 - accuracy: 0.9799\n",
      "loss: 0.06663481146097183\n",
      "accuracy: 0.9799000024795532\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y, verbose=2)\n",
    "print('loss:', loss)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 모델을 테스트해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.59171207e-08 3.28807982e-05 1.74319172e-08 2.36964246e-04\n",
      "  5.96795406e-04 1.36022678e-07 7.04254710e-11 3.45475762e-03\n",
      "  5.78827830e-08 9.95678365e-01]\n",
      " [9.96910632e-01 4.51320190e-08 3.03420802e-06 2.58842388e-08\n",
      "  1.31931701e-08 3.56861012e-04 2.71601300e-03 9.83215045e-07\n",
      "  9.80830137e-08 1.23790187e-05]\n",
      " [1.44733775e-07 1.45485241e-03 9.95113313e-01 2.28903303e-03\n",
      "  4.70110929e-13 1.15247696e-08 5.26852728e-10 1.51737865e-07\n",
      "  1.14263978e-03 2.23354046e-08]\n",
      " [4.11488725e-12 1.09613235e-10 8.36125658e-09 4.47153393e-03\n",
      "  3.35126759e-16 9.95523930e-01 6.84527250e-13 5.59760961e-15\n",
      "  1.93392353e-07 4.27169198e-06]\n",
      " [2.54386165e-08 9.98593509e-01 5.05135995e-06 2.49347970e-04\n",
      "  1.52708948e-04 6.00270432e-05 2.51744605e-05 3.28932656e-05\n",
      "  8.56584113e-04 2.47955377e-05]]\n"
     ]
    }
   ],
   "source": [
    "xhat = test_x[1000:1005]\n",
    "yhat = model.predict(xhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최댓값을 찾아 test_y의 답안과 비교해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내 모델의 답안: 9 ,  실제 답안: 9   (정답)\n",
      "내 모델의 답안: 0 ,  실제 답안: 0   (정답)\n",
      "내 모델의 답안: 2 ,  실제 답안: 2   (정답)\n",
      "내 모델의 답안: 5 ,  실제 답안: 5   (정답)\n",
      "내 모델의 답안: 1 ,  실제 답안: 1   (정답)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('내 모델의 답안:', np.argmax(yhat[i]), ',  실제 답안:', test_y[1000+i], end='')\n",
    "    if np.argmax(yhat[i]) == test_y[1000+i]:\n",
    "        print('   (정답)')\n",
    "    else:\n",
    "        print('   (오답)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANZElEQVR4nO3df6zV9X3H8ddLQJygC1TBW2DCWrrWrBltr9jFZbG1Gur+QLu6lnWOpqZ0pmbt1q6zmEySZQtbV7uu1VospNhVjYk6SUY2CdM505V5JQyh1GEN6hUCNCwT14r8eO+P+2W56D2fczm/vof7fj6Sm3PO932+3+87J7z4fs/5fM/5OCIEYOI7q+4GAPQGYQeSIOxAEoQdSIKwA0lM7uXOzvbUOEfTerlLIJXX9L96PY54rFpbYbe9RNLXJU2S9J2IWF16/jmapst8ZTu7BFCwJTY3rLV8Gm97kqQ7JH1Y0iWSltm+pNXtAeiudt6zL5b0XEQ8HxGvS7pf0tLOtAWg09oJ+xxJL416PFwtO4XtFbaHbA8d1ZE2dgegHe2EfawPAd507W1ErImIwYgYnKKpbewOQDvaCfuwpHmjHs+VtLe9dgB0Szthf0rSQtsLbJ8t6eOSNnSmLQCd1vLQW0Qcs32zpH/WyNDbuojY2bHOAHRUW+PsEbFR0sYO9QKgi7hcFkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BEW1M2294j6bCk45KORcRgJ5oC0Hlthb3ygYj4aQe2A6CLOI0Hkmg37CHpUdtP214x1hNsr7A9ZHvoqI60uTsArWr3NP7yiNhre5akTbZ/HBFPjH5CRKyRtEaSzvfMaHN/AFrU1pE9IvZWtwckPSxpcSeaAtB5LYfd9jTb5528L+lqSTs61RiAzmrnNH62pIdtn9zOvRHxTx3pCkDHtRz2iHhe0q91sBcAXcTQG5AEYQeSIOxAEoQdSIKwA0l04oswOJMtfnexfPB904v1u770d+XNT53SsHY8ThTXveTJTxbr8z+2vVjHqTiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjujdj8ec75lxma/s2f7Q3Cd+PFyun3egR5282c/j9WL9sjv/uFif+5c/6GQ7Z4QtsVmvxCGPVePIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ8H32CW7SY28t1j8y/YdNtnB255o5Tb/g8r5PNP6qPMbAkR1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfYJbveChYv21OF6sv/8bNxfrc//lcLH+8srG29+2+O+L66Kzmh7Zba+zfcD2jlHLZtreZHt3dTuju20CaNd4TuO/K2nJG5bdImlzRCyUtLl6DKCPNQ17RDwh6dAbFi+VtL66v17StR3uC0CHtfoB3eyI2CdJ1e2sRk+0vcL2kO2hozrS4u4AtKvrn8ZHxJqIGIyIwSma2u3dAWig1bDvtz0gSdVtfT9BCmBcWg37BknLq/vLJT3SmXYAdEvTcXbb90m6QtIFtocl3SZptaQHbN8o6UVJ13ezSZT50sZzrM8868niuh979neL9Tl/Vf7t9ThrUrH+7lnnF+vonaZhj4hlDUrM9gCcQbhcFkiCsANJEHYgCcIOJEHYgST4iusEMPzlEw1rA5POLa77nYX3Fus3XXpTsf6T355erG+cf0ex3o7X5pWndMapOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs08APxsujHVfVl73lyaXx+H/8R/WF+t1Ouel+qaTPhNxZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnnwDe+Y2DDWsvX/uz4rpzmnzfHRMHR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9gng+O7nG9Y+dO+fFNf9wAe3Fes3Xfh4sX7DnX9UrP/tH3y7Ye2Kc44W1737f+YV6wvu3F2sHy9W82l6ZLe9zvYB2ztGLVtl+2Xb26q/a7rbJoB2jec0/ruSloyx/GsRsaj629jZtgB0WtOwR8QTkg71oBcAXdTOB3Q3295enebPaPQk2ytsD9keOqojbewOQDtaDfu3JL1N0iJJ+yR9tdETI2JNRAxGxOAUTW1xdwDa1VLYI2J/RByPiBOS7pa0uLNtAei0lsJue2DUw+sk7Wj0XAD9oek4u+37JF0h6QLbw5Juk3SF7UWSQtIeSZ/pYo9ow4Jb/r1Y39Nk/Vsv/mix/uqfledIbzaWXnLXXUuL9dkHf9DytjNqGvaIWDbG4rVd6AVAF3G5LJAEYQeSIOxAEoQdSIKwA0nwFVcUHfjg3GL93676SpMtNP6p6g/96LrimrO/uaXJtnE6OLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsyc3afasYv33v1j+LdGBJlM+HzjeeMroSX/xluK6OvFCuY7TwpEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH2Cm3xxedrj2x5/qFh/39mTivVjTSZGXnL7lxrWLnqcn4LuJY7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+wT3GtrXaw3G0dv5tf//A+L9YvuYiy9XzQ9stueZ/sx27ts77T9uWr5TNubbO+ubmd0v10ArRrPafwxSV+IiHdJer+kz9q+RNItkjZHxEJJm6vHAPpU07BHxL6I2FrdPyxpl6Q5kpZKWl89bb2ka7vVJID2ndYHdLbnS3qPpC2SZkfEPmnkPwRJY/6Yme0VtodsDx3Vkfa6BdCycYfd9nRJD0r6fES8Mt71ImJNRAxGxOAUTW2lRwAdMK6w256ikaB/PyJOfk1qv+2Bqj4g6UB3WgTQCU2H3mxb0lpJuyLi9lGlDZKWS1pd3T7SlQ7R1O573tuw9uy77i6u+73DA8X6/b93dbF+4db/KNbRP8Yzzn65pBskPWN7W7VspUZC/oDtGyW9KOn67rQIoBOahj0inpTU6MqMKzvbDoBu4XJZIAnCDiRB2IEkCDuQBGEHkuArrv3grPLXTF9YtbhYf/bKbzasvXjs58V11375umL93KEtxTrOHBzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtn7wKsfvbRY33njHU220Pjnoj+x8ovFNX/x4R822TYmCo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+w9MHnOW4v1e77yN022cG6x+vZHP92w9isPbC2uG032jImDIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJDGe+dnnSbpH0kWSTkhaExFft71K0qclHayeujIiNnar0TPZ8PXzi/X5k8vj6O/8108V6+/4VOOx9AhG0jFiPBfVHJP0hYjYavs8SU/b3lTVvhYRza4IAdAHxjM/+z5J+6r7h23vkjSn240B6KzTes9ue76k90g6OSfQzba3215ne0aDdVbYHrI9dFRH2moWQOvGHXbb0yU9KOnzEfGKpG9JepukRRo58n91rPUiYk1EDEbE4BRN7UDLAFoxrrDbnqKRoH8/Ih6SpIjYHxHHI+KEpLsllWcfBFCrpmG3bUlrJe2KiNtHLR8Y9bTrJO3ofHsAOmU8n8ZfLukGSc/Y3lYtWylpme1FGvmW5B5Jn+lKhxPA1KsOFutrX5lbrL/j1v8u1o8xvIZxGM+n8U9q7B8mZ0wdOINwBR2QBGEHkiDsQBKEHUiCsANJEHYgCX5Kugdm/NbuYv1BzWqyhRc61wzS4sgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0m4lz81bPugTh00vkDST3vWwOnp1976tS+J3lrVyd4ujogLxyr0NOxv2rk9FBGDtTVQ0K+99WtfEr21qle9cRoPJEHYgSTqDvuamvdf0q+99WtfEr21qie91fqeHUDv1H1kB9AjhB1Iopaw215i+1nbz9m+pY4eGrG9x/YztrfZHqq5l3W2D9jeMWrZTNubbO+ubsecY6+m3lbZfrl67bbZvqam3ubZfsz2Lts7bX+uWl7ra1foqyevW8/fs9ueJOm/JF0laVjSU5KWRcSPetpIA7b3SBqMiNovwLD9m5JelXRPRPxqteyvJR2KiNXVf5QzIuJP+6S3VZJerXsa72q2ooHR04xLulbSJ1Xja1fo63fUg9etjiP7YknPRcTzEfG6pPslLa2hj74XEU9IOvSGxUslra/ur9fIP5aea9BbX4iIfRGxtbp/WNLJacZrfe0KffVEHWGfI+mlUY+H1V/zvYekR20/bXtF3c2MYXZE7JNG/vFITX/TqteaTuPdS2+YZrxvXrtWpj9vVx1hH2sqqX4a/7s8It4r6cOSPludrmJ8xjWNd6+MMc14X2h1+vN21RH2YUnzRj2eK2lvDX2MKSL2VrcHJD2s/puKev/JGXSr2wM19/P/+mka77GmGVcfvHZ1Tn9eR9ifkrTQ9gLbZ0v6uKQNNfTxJranVR+cyPY0SVer/6ai3iBpeXV/uaRHauzlFP0yjXejacZV82tX+/TnEdHzP0nXaOQT+Z9IurWOHhr09cuS/rP621l3b5Lu08hp3VGNnBHdKOktkjZL2l3dzuyj3r4n6RlJ2zUSrIGaevsNjbw13C5pW/V3Td2vXaGvnrxuXC4LJMEVdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8B6fTlvTMcSHQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAORElEQVR4nO3de4xc9XnG8eexs7aFgeILBseYa60WmgZoVtBClRAQCaAgc1ESUJNShOq0BTW0VCpKpUKF2qC0geZCiEyxcCMCRWBqRyIJxEVCCGqxEAJ2HcolBtZ2ccA0EBzM2n77x46rBfb8Zj1nbrvv9yOtZva885vz6uw+e2bnnDM/R4QATH3Tet0AgO4g7EAShB1IgrADSRB2IIkPdHNlMzwzZml2N1cJpPK23tI7sdPj1WqF3fZZkr4mabqkf4mI60uPn6XZOtln1FklgIJ1sbay1vLLeNvTJd0k6WxJx0m62PZxrT4fgM6q8z/7SZKei4gXIuIdSXdKWtqetgC0W52wL5L08pjvhxvL3sX2MttDtodGtLPG6gDUUSfs470J8L5zbyNieUQMRsTggGbWWB2AOuqEfVjS4jHfHyZpS712AHRKnbA/JmmJ7aNsz5B0kaQ17WkLQLu1fOgtInbZvkLSDzV66G1FRGxoW2cA2qrWcfaIuE/SfW3qBUAHcboskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0l0dcpm9J/pB/1asb7twvJcnUPX3Vysf3xD9fR/v1j1weLYg29+tFjHvmHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJcJw9uU2X/1ax/uM/+1qxPhLl/cUPjru7srb6iPnFsX976B8U60dc80ixjnerFXbbmyS9KWm3pF0RMdiOpgC0Xzv27B+PiFfb8DwAOoj/2YEk6oY9JN1v+3Hby8Z7gO1ltodsD41oZ83VAWhV3Zfxp0bEFtsLJD1g+6cR8dDYB0TEcknLJelAz42a6wPQolp79ojY0rjdJuleSSe1oykA7ddy2G3Ptn3A3vuSPiFpfbsaA9BedV7GHyLpXtt7n+e7EfGDtnSFfbLnYydW1l67akdx7PeO/0qTZ5/ZQkcTs3R2+SDOgs99u1j/8jUfbmc7U17LYY+IFyQd38ZeAHQQh96AJAg7kARhB5Ig7EAShB1Igktcp4DnL5xRWdv4keVNRtc7tHbqkxcV69Nvn1dZm/aH24pj/37Jv7fUE8bHnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuA4+yTwgcMWFeurzv16oVrv7/mHH76sWD/ys081eYZnKytbFp1SHHnAb7xdrDfbLruGNxfr2bBnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkOM4+Cby1YqBYP3ZG63+z/+Tl04v1oy99rljf0/KapYOe312s//pAuX7o3b8o1v/nwg9W1nZt3lIcOxWxZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjO3gemLzm6WL/yqPtbfu4f/eqAYn3zX5bX7R0/aXndzey3al2xPnxDefy3Fj9YrJ/1oT+trM3gOPv72V5he5vt9WOWzbX9gO1nG7dzOtsmgLom8jL+NklnvWfZ1ZLWRsQSSWsb3wPoY03DHhEPSdr+nsVLJa1s3F8p6bw29wWgzVp9g+6QiNgqSY3bBVUPtL3M9pDtoRHtbHF1AOrq+LvxEbE8IgYjYnCg5iSCAFrXathfsb1Qkhq35ek4AfRcq2FfI+mSxv1LJK1uTzsAOqXpcXbbd0g6TdJ828OSrpF0vaS7bF8m6SVJn+5kk1Pd9pMr3/KQJJ293+vF+khUX/d9zZcvLY6d98ijxXovnfu9K4v1jRd8s1gfPr36cwCO/mFLLU1qTcMeERdXlM5ocy8AOojTZYEkCDuQBGEHkiDsQBKEHUiCS1y7YNp++xXrx16xodbzf3378ZW1ebf276G1Zma/OL3W+N/7aPV2/XmTn8meHTtqrbsfsWcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQ4zt4F0xbML9a/vfieWs+/6hvV0y7P0+Q9zn743cPlB/xFuXzL4WsraxfMO784luPsACYtwg4kQdiBJAg7kARhB5Ig7EAShB1IguPsXbDxrxYW69Oa/M0d3vWrYv2Q+16srO0qjpzcmm238mC3r5FJgj07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcfZuiHJ5j/YU6+f9+I+L9UM3b9zXjiaFt485uFhvtt3Kg5v8UKagpnt22ytsb7O9fsyya21vtv1k4+uczrYJoK6JvIy/TdJZ4yy/MSJOaHzd1962ALRb07BHxEOStnehFwAdVOcNuitsP9V4mT+n6kG2l9kesj00op01VgegjlbDfrOkYySdIGmrpK9WPTAilkfEYEQMDmhmi6sDUFdLYY+IVyJid0TskXSLpJPa2xaAdmsp7LbHXrN5vqT1VY8F0B+aHme3fYek0yTNtz0s6RpJp9k+QaNHkDdJ+kIHe0RSPzuv3mkgd7y5qLIWU/Bz4ZtpujUj4uJxFt/agV4AdBCnywJJEHYgCcIOJEHYgSQIO5AEl7hOAvvPanKa8bTp1bU9u9vbTBed8pFnao2/8adnVNYOfW1qXhZcwp4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5LgOHsXLL6/yccWX1Au/8dv/1ux/qlTqj9qetrDT5afvIfeuvDkYv2uw/+5yTPw67sv2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIcqOyC2f/5s2J99Vvzi/Wls18t1q+87c7K2t9dd2lx7JyVjxbrnbT5zPL5B7Nc79dz5r0H1Ro/1bBnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNHkWus2OtBz42RXf5Z3VjsuKF/X/aNvfLPl535hZKRYv/nVjxXr31872PK6JensM4Yqa9cd+lBx7Pbd5c+8P2P1VcX6b970WmVt9zPPFcdOVutird6I7R6v1nTPbnux7Qdtb7S9wfYXG8vn2n7A9rON2zntbhxA+0zkZfwuSVdFxLGSflfS5baPk3S1pLURsUTS2sb3APpU07BHxNaIeKJx/01JGyUtkrRU0srGw1ZKOq9TTQKob5/eoLN9pKQTJa2TdEhEbJVG/yBIWlAxZpntIdtDI2oyZxmAjplw2G3vL+keSVdGxBsTHRcRyyNiMCIGBzSzlR4BtMGEwm57QKNBvz0iVjUWv2J7YaO+UNK2zrQIoB2aXkNo25JulbQxIm4YU1oj6RJJ1zduV3ekwwRmbSv/e/P9HeUDHWfv93pl7eiBgeLYf1z4SLn+uXJ9WpP9xR7tKVTLv34v7ppdrC/583XF+uSdrLozJnLB8KmSPi/padt7P4T8SxoN+V22L5P0kqRPd6ZFAO3QNOwR8bCkcQ/SS+IMGWCS4HRZIAnCDiRB2IEkCDuQBGEHkuCjpPtAs2mVbznz9GL9H26qPjPximMeLI797AFbi/Veumv7SU0e8XZX+pgq2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBIcZ58Edm16qVifc+70ytp3T/xkceyBd5Y/hqB0rfxEfHJD9ZXPh+3/v8Wxr3+mfD27tLmFjvJizw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTBlMzCF1JqyGcDUQNiBJAg7kARhB5Ig7EAShB1IgrADSTQNu+3Fth+0vdH2BttfbCy/1vZm2082vs7pfLsAWjWRD6/YJemqiHjC9gGSHrf9QKN2Y0T8U+faA9AuE5mffaukrY37b9reKGlRpxsD0F779D+77SMlnShpXWPRFbafsr3C9pyKMctsD9keGtHOWs0CaN2Ew257f0n3SLoyIt6QdLOkYySdoNE9/1fHGxcRyyNiMCIGB1Q9JxmAzppQ2G0PaDTot0fEKkmKiFciYndE7JF0i6Rms/AB6KGJvBtvSbdK2hgRN4xZvnDMw86XtL797QFol4m8G3+qpM9Letr23rmFvyTpYtsnSApJmyR9oSMdAmiLibwb/7Ck8a6Pva/97QDoFM6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNHVKZtt/1zSi2MWzZf0atca2Df92lu/9iXRW6va2dsREXHweIWuhv19K7eHImKwZw0U9Gtv/dqXRG+t6lZvvIwHkiDsQBK9DvvyHq+/pF9769e+JHprVVd66+n/7AC6p9d7dgBdQtiBJHoSdttn2X7G9nO2r+5FD1Vsb7L9dGMa6qEe97LC9jbb68csm2v7AdvPNm7HnWOvR731xTTehWnGe7rtej39edf/Z7c9XdJ/SzpT0rCkxyRdHBH/1dVGKtjeJGkwInp+Aobtj0r6paR/jYgPNZZ9RdL2iLi+8YdyTkT8dZ/0dq2kX/Z6Gu/GbEULx04zLuk8SX+kHm67Ql+fURe2Wy/27CdJei4iXoiIdyTdKWlpD/roexHxkKTt71m8VNLKxv2VGv1l6bqK3vpCRGyNiCca99+UtHea8Z5uu0JfXdGLsC+S9PKY74fVX/O9h6T7bT9ue1mvmxnHIRGxVRr95ZG0oMf9vFfTaby76T3TjPfNtmtl+vO6ehH28aaS6qfjf6dGxO9IOlvS5Y2Xq5iYCU3j3S3jTDPeF1qd/ryuXoR9WNLiMd8fJmlLD/oYV0Rsadxuk3Sv+m8q6lf2zqDbuN3W437+Xz9N4z3eNOPqg23Xy+nPexH2xyQtsX2U7RmSLpK0pgd9vI/t2Y03TmR7tqRPqP+mol4j6ZLG/Uskre5hL+/SL9N4V00zrh5vu55Pfx4RXf+SdI5G35F/XtLf9KKHir6OlvSTxteGXvcm6Q6Nvqwb0egrosskzZO0VtKzjdu5fdTbdyQ9LekpjQZrYY96+32N/mv4lKQnG1/n9HrbFfrqynbjdFkgCc6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/g/l4iuPF582lgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for image in test_x[1000:1005]:\n",
    "    plt.figure()\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras를 install하여 직접 이용해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense as Dense2, Dropout as Dropout2, Activation as Activation2, Flatten as Flatten2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.add(Flatten2(input_shape=(28, 28)))\n",
    "model_2.add(Dense2(128))\n",
    "model_2.add(Activation2('relu'))\n",
    "model_2.add(Dropout2(0.2))\n",
    "model_2.add(Dense2(10))\n",
    "model_2.add(Activation2('softmax'))\n",
    "model_2.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2964 - accuracy: 0.9141\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 2s 812us/step - loss: 0.1418 - accuracy: 0.9572\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 2s 859us/step - loss: 0.1082 - accuracy: 0.9667\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0874 - accuracy: 0.9732\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0744 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x256a05ad850>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_x, train_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 0s - loss: 0.0741 - accuracy: 0.9763\n",
      "loss: 0.07406604290008545\n",
      "accuracy: 0.9763000011444092\n"
     ]
    }
   ],
   "source": [
    "loss2, accuracy2 = model_2.evaluate(test_x, test_y, verbose=2)\n",
    "print('loss:', loss2)\n",
    "print('accuracy:', accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 학습된 모델 저장하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 코드의 주석을 풀고 실행시키면 jupyter notebook 파일 위치에 학습된 model 파일이 생성된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('mnist_model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다음 코드의 주석을 풀고 실행시키면 jupyter notebook 파일과 같은 위치에 해당 모델 파일이 존재할 경우 불러올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model = load_model('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 전이학습(Transfer Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50을 불러오는 코드 및 구조는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "resnet = ResNet50()\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전이학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전학습모델(pre-trained model)에 fitting을 이어나가면 더 높은 정확도를 얻을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-2af114a6076e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresnet_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'avg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresnet_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mresnet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resnet_path' is not defined"
     ]
    }
   ],
   "source": [
    "resnet_model = Sequential()\n",
    "resnet_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_path))\n",
    "resnet_model.add(Dropout(0.50))\n",
    "resnet_model.add(Dense(10))\n",
    "resnet_model.add(Activation('softmax'))\n",
    "resnet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(\"input_2:0\", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 28, 28).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 28, 28]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ce37644eabdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m# decode the results into a list of tuples (class, description, probability)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# (one such list for each sample in the batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1418 predict_step\n        return self(x, training=False)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:385 call\n        return self._run_internal_graph(\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 28, 28]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "mymodel = ResNet50(weights='imagenet')\n",
    "\n",
    "x = train_x[1000]\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = mymodel.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
