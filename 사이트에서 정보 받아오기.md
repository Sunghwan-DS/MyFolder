# 사이트에서 정보 받아오기

### 1. 정보를 받고자 하는 사이트의 url 복붙

>melon_url = 'https://www.melon.com/chart/index.htm'



#### `response = requests.get(melon_url)` 하여 print(response)가 200이 아닌 400대가 나온다면

> 개발자 창에서 Network - index.htm 맨 하단 User-Agent를 복사하여

``` python
melon_url = 'https://www.melon.com/chart/index.htm'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'
}
response = requests.get(melon_url, headers=headers).text
# requests를 사용하기 위해 import requests 필수
```

> 와 같이 작성한다.



### 2. 사이트로부터 모든 text 를 받아온다음 'html.parser'로 처리해준다.

```python
response = requests.get(melon_url, headers=headers).text
data = BeautifulSoup(response, 'html.parser')
#  BeautifulSoup를 사용하기 위해 from bs4 import BeautifulSoup 는 필수
```



### 3. 가져올 데이터의 copy selector를 복붙해온다.

```python
rankings = data.select('#lst50 > td:nth-child(6) > div > div > div.ellipsis.rank01 > span > a')
```

현재 rankings에 저장된 데이터는 내가 가져오고자 하는 부분에서의 링크+text 이다.

절대 내가 원하는 정보만을 담고있는 것이 아니라는게 중요하다.



### 4. 원하는 자료는 오직 text 이므로 text만을 dictionary 형태로 저장 및 관리하여야 한다.

```python
result_dict = {}
result_list = []
for idx, ranking in enumerate(rankings, 1):
    # print(f'{idx}위: {ranking.text}')
    # result_dict[f'{idx}위'] = ranking.text
    result_dict = {'rank': f'{idx}위', 'ranker':ranking.text}
    result_list.append(result_dict)
# pprint(result_list)
for a in result_list:
    print(a['rank'], a['ranker'])
```

